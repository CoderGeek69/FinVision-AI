#Import .csv File containing Financial Data
import csv
with open('C:/Users/91891/OneDrive/Desktop/FINDAT 16-24 - FINAL DATASET.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)

#Import necessary libraries
import csv
import pandas as pd

#Import.csv File containing Financial Data
data = pd.read_csv('C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv')
import csv

import pandas as pd

# Load the dataset
data = pd.read_csv('C:/Users/91891/OneDrive/Desktop/FINDAT 16-24 - FINAL DATASET.csv')

# Slice the DataFrame from row 2 to the end
data = data.iloc[1:, :]

# Display the first 5 rows of the sliced DataFrame
print(data.head())

print(data)

#Convert the Date column to a float variable
import pandas as pd

# load the CSV file into a DataFrame
data = pd.read_csv('C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv')

# convert the 'Date' column to a datetime format
data['Date'] = pd.to_datetime(data['Date'])

# print the column names
print(data.columns)

# access the 'row[1:]' column
if 'row' in data and not isinstance(data['row'], (list, tuple)):
    data['row'] = [data['row']]

# convert datetime to float
data['Date_Float'] = data['Date'].apply(lambda x: x.toordinal())


print("STEP-1 COMPLETE")


import pandas as pd

file_path = "C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv"
data = pd.read_csv(file_path, skiprows=1)

# Ensure the 'Date' column exists before attempting to convert
if 'Date' in data.columns:
    data['Date'] = pd.to_numeric(data['Date'], errors='coerce')
    # Handle potential NaN values resulting from coercion
    data['Date'].fillna(data['Date'].mean(), inplace=True)  # or some other suitable fill method
else:
    print("Warning: 'Date' column not found in the data.")

#Print the first 5 rows of the cleaned data
print(data.head())

#Import.csv File containing Financial Data
data = pd.read_csv('C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv')

#Remove any rows with missing values
data = data.dropna()

#Convert categorical variables into dummy/indicator variables
data = pd.get_dummies(data)

#Print the first 5 rows of the cleaned data
print(data.head())
# Convert string to float
def convert_string_to_float(x):
    try:
        return float(x.strip())
    except ValueError:
        return np.nan
import csv

# Open the CSV file and read its contents
with open('C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv', 'r') as csvfile:
    # Create a CSV reader object
    csvreader = csv.reader(csvfile)

    # Loop through each row in the CSV file
    for row in csvreader:
# Convert the string to a float and store it in a variable
        try:
            value = float(row[0].strip())
        except ValueError:
            print(f"Error: Cannot convert '{row[0]}' to float.")
            value = None  # or some other default value  # Assuming the input is in the first column
    def skip_first_column(data):
        return [row[1:] for row in data]

print("STEP-2 COMPLETE")

input_string = "C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv"
file_path = r"C:\Users\91891\OneDrive\Desktop\FINDAT 16-24 - FINAL DATASET (4).csv"
with open(file_path, 'r') as f:
    for line in f:
        row = line.strip().split(',')
        if len(row) > 0:
            try:
                value = float(row[0])
                print(f"The float value of '{row[0]}' is: {value:.2f}")
            except ValueError:
                print(f"Error: Cannot convert '{row[0]}' to float.")
#Clean Data
import pandas as pd
data = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
data.dropna(inplace=True)
data.drop_duplicates(inplace=True)
data = data.applymap(lambda x: x.lower() if isinstance(x, str) else x)
data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)
data.to_csv("cleaned_data.csv", index=False)
#Differencing
import pandas as pd
data = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
import pandas as pd
df = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
df = pd.get_dummies(df, drop_first=True)
df = df.fillna(df.mean())
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

print("STEP-3 COMPLETE")

# Import necessary libraries
import pandas as pd
import numpy as np

# Load the data into a DataFrame
df = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
# Import the necessary library
from sklearn.preprocessing import MinMaxScaler

# Initialize a scaler with a range of 0 to 1
scaler = MinMaxScaler()

# Fit and transform the dataframe 'df' using the scaler
df_scaled = scaler.fit_transform(df)
y = df_scaled['Shares Traded']
X = df_scaled.drop('Shares Traded', axis=1)

X_1d = X.values.reshape(-1)

def convert_string_to_float(x):
    try:
        return float(x.strip())
    except ValueError:
        return np.nan

# Import necessary libraries
import pandas as pd
import numpy as np

# Load the data into a DataFrame
df = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
df = df.applymap(convert_string_to_float)

#Preprocess for modelling
import pandas as pd
data = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

#Introduce Modelling system ARIMA

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error

data = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv", index_col='Date', parse_dates=True)

# Check for any missing values
if data.isnull().values.any():
    print("Data contains missing values. Please handle them before proceeding.")
else:
    print("Data does not contain any missing values.")

if data.duplicated().any():
    print("Data contains duplicate values. Please handle them before proceeding.")
else:
    print("Data does not contain any duplicate values.")

# Check for any outliers
q1 = data.quantile(0.25)
q3 = data.quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

if data[(data < lower_bound) | (data > upper_bound)].any().any():
    print("Data contains outliers. Please handle them before proceeding.")
else:
    print("Data does not contain any outliers.")

from statsmodels.tsa.stattools import adfuller

def test_stationarity(timeseries):
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])
    for key, value in dftest[4].items():
        dfoutput['Critical Value (%s)' % key] = value
    print(dfoutput)

test_stationarity(data)

if data[0]!= 0:
    data_diff = data.diff().dropna()
    test_stationarity(data_diff)
else:
    print("Data is already stationary.")

# Train the ARIMA model
model = ARIMA(data_diff, order=(5,1,0))
model_fit = model.fit()

data_diff = ["C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv"] 
test = ["C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv"]   

total_length = len(data_diff) + len(test)

# Make predictions
predictions = model_fit.predict(
    start=len(data_diff), 
    end=len(data_diff) + len(test), 
    typ='levels'
)

# Evaluate the model
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_true=test, y_pred=predictions)
print(f"Test MSE: {mse:.3f}")

#Run Diagnostics on data differencing and Analysis, improve any faults ASAP
import pandas as pd
df = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv")
print(df.head())
# Import necessary libraries
import pandas as pd
import numpy as np
from matplotlib import pyplot
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error


data = pd.read_csv("C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv", index_col='Date', parse_dates=True)
print("Missing values: ", data.isnull().sum())
differenced_data = data.diff().dropna()
model = ARIMA(differenced_data, order=(5,1,0))
model_fit = model.fit()

predictions = model_fit.forecast(steps=len(test))
mse = mean_squared_error(y_true=test, y_pred=predictions)
print(f"Test MSE: {mse:.3f}")

# Plot the original data and the predictions to visually inspect the fit
pyplot.plot(data)
pyplot.plot(predictions, color='red')
pyplot.show()

# Load the dataset
import pandas as pd

file_path = "C:\\Users\\91891\\OneDrive\\Desktop\\FINDAT 16-24 - FINAL DATASET (4).csv"
data = pd.read_csv(file_path, index_col='Date', parse_dates=True)

if data.isnull().values.any():
    print("Data contains missing values. Please handle them before proceeding.")
else:
    print("Data does not contain any missing values.")

# Check for any duplicate values
if data.duplicated().any():
    print("Data contains duplicate values. Please handle them before proceeding.")
else:
    print("Data does not contain any duplicate values.")

# Check for any outliers
q1 = data.quantile(0.25)
q3 = data.quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

if data[(data < lower_bound) | (data > upper_bound)].any().any():
    print("Data contains outliers. Please handle them before proceeding.")
else:
    print("Data does not contain any outliers.")

# Check for stationarity
        #Import Statsmodels using something i dont know about
import statsmodels
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.stattools import adfuller

def test_stationarity(timeseries):
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])
    for key, value in dftest[4].items():
        dfoutput['Critical Value (%s)' % key] = value
    print(dfoutput)

test_stationarity(data)

# If the data is not stationary, perform differencing
if data[0]!= 0:
    data_diff = data.diff().dropna()
    test_stationarity(data_diff)
else:
    print("Data is already stationary.")

# Train the ARIMA model
model = ARIMA(data_diff, order=(5,1,0))
model_fit = model.fit()

# Make predictions
predictions = model_fit.predict(start=len(data_diff), end=len(data_diff)+len(test), typ='levels')

# Evaluate the model
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(test, predictions)

print('Test MSE: %.3f' % mse)